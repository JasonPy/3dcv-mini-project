{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Pose Estimation\n",
    "\n",
    "This notebook contains more detailed information on how to use the 7-scenes data set and apply the regression forest with consecutive RANSAC optimization. For detailed information regarding the implementation read our documentation in the **readme.md** file or inspect the comments in the code. For the mathematical background as well as architectural decisions please refer to the corresponding report in the **./report** directory.\n",
    "\n",
    "At first, we show how to download and clean the data set for a certain scene. Then, the use of the Regresion Forest and RANSAC algorithm is shown and obtained results are subsequently analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not provide a full package yet and load our python files manually\n",
    "import sys\n",
    "sys.path.append('./source/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Data Loading\n",
    "In order to get started we first need to download data from the [**7-scenes dataset**](https://www.microsoft.com/en-us/research/project/rgb-d-dataset-7-scenes/). Therefore, just hop into the **/data** folder where you will find a notebook called **load_and_clean_7_scenes_dataset.ipynb**. Just pick a scene of your choice and execute the corresponding cell. \n",
    "\n",
    "To get an intuition for the data, we plot a number of `SAMPLES` of random images and corresponding depth maps from the data set `SCENE`. Additionally, the full volumetric image of the scene is displayed. \n",
    "\n",
    "Feel free to play around with different scenes in this notebook assuming the corresponding data set has been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from source.data_loader import DataLoader \n",
    "\n",
    "SCENE = \"stairs\"         # one of the scenes (name of folder in /data)\n",
    "DATA_PATH = \"./data\"    # directory where image data is stored\n",
    "SAMPLES = 4             # images to display \n",
    "\n",
    "# load the data set\n",
    "loader = DataLoader(DATA_PATH)\n",
    "indices = np.random.choice(loader.get_dataset_length(SCENE), SAMPLES, replace = False)\n",
    "images, depths, poses = loader.load_dataset(SCENE, indices)\n",
    "\n",
    "# plot random images \n",
    "_, axes = plt.subplots(2, SAMPLES, figsize=(12,6))\n",
    "for i in range(SAMPLES):\n",
    "    axes[0,i].imshow(np.swapaxes(images[i], 1, 0))\n",
    "    axes[1,i].imshow(depths[i].T, cmap=plt.get_cmap(\"plasma\"))\n",
    "plt.show()\n",
    "\n",
    "# plot volume\n",
    "full_scene = np.array(Image.open(f\"./data/{SCENE}/{SCENE}.png\"))\n",
    "plt.imshow(full_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Regression Forest\n",
    "In this section we provide an approach on how to use our implementation of the Regression Forest. Therefore, we show any hyperparameters used for training and show the results of a trained forest. Look into the **/output** directory to get an overview of pre-trained forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training\n",
    "To train a forest for a certain scene we provide the script **/source/train_forest.py**. Initially, all hyperparameters must be set and are displayed in the following table:\n",
    "\n",
    "| Hyperparameter | Default        | \n",
    "| ------------- |:-------------:| \n",
    "|TEST_SIZE | *0.5* |\n",
    "|NUM_TREES | 5 |\n",
    "|TREE_MAX_DEPTH | 16 |\n",
    "|NUM_TRAIN_IMAGES_PER_TREE | 500 |\n",
    "|NUM_SAMPLES_PER_IMAGE | 5000   |\n",
    "|NUM_PARAMETER_SAMPLES | 1024 |\n",
    "|FEATURE_TYPE | *DA_RGB / DEPTH* |\n",
    "\n",
    "Make sure to  adjust the test size for each dataset since the values vary among different scenes. Subsequently, the dataset is loaded and split into training and test data. The forest is initialized and the training process started. When the training is finished, the forest object and corresponding parameters are saved in the **/output** folder.\n",
    "\n",
    "Here, we load a trained forest and display the hypperparameters that have been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from source.utils import load_object, millis\n",
    "\n",
    "OUTPUT = \"./output\"\n",
    "PREFIX = \"26-03-2022_10-37_stairs\"    # folder which contains trained forest and parameters file\n",
    "\n",
    "params = load_object(os.path.join(OUTPUT, PREFIX, f\"params_{SCENE}.pkl\"))\n",
    "print(f'Loading forest trained on \"{SCENE}\"')\n",
    "\n",
    "[print(f'\\t{key}: {params[key]}') for key in [\n",
    "    'TIMESTAMP',\n",
    "    'TREE_MAX_DEPTH',\n",
    "    'NUM_TREES',\n",
    "    'NUM_TRAIN_IMAGES_PER_TREE',\n",
    "    'NUM_SAMPLES_PER_IMAGE',\n",
    "    'NUM_PARAMETER_SAMPLES',\n",
    "    'FEATURE_TYPE']]\n",
    "    \n",
    "forest = load_object(os.path.join(OUTPUT, PREFIX, f\"trained_forest_{SCENE}.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Testing\n",
    "Now, we can use the trained forest and see how it performs on unseen data. Therefore, the forest is evaluated with randomly sampled test images. The number of test images is specified as `NUM_TEST_IMAGES` and the number of sampled pixels per image is defined as `NUM_SAMPLES_PER_IMAGE`. The resulting array contains the valid predictions of every tree in the forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_IMAGES = 500\n",
    "NUM_SAMPLES_PER_IMAGE = 5000\n",
    "\n",
    "# Sample images from test data set\n",
    "test_set_indices = params['TEST_INDICES']\n",
    "test_indices = np.random.choice(test_set_indices, NUM_TEST_IMAGES, replace = False)\n",
    "images_data = loader.load_dataset(SCENE, test_indices)\n",
    "\n",
    "# Obtain pixel and world coordinates from sample points\n",
    "p_s, w_s = loader.sample_from_data_set(\n",
    "    images_data = images_data,\n",
    "    num_samples = NUM_SAMPLES_PER_IMAGE)\n",
    "\n",
    "# Evalulate forest\n",
    "print(f'Evaluating Forest with {NUM_TEST_IMAGES * NUM_SAMPLES_PER_IMAGE} samples per tree...')\n",
    "\n",
    "start = millis()\n",
    "forest_predictions = forest.evaluate(p_s, images_data)\n",
    "print(f'Finished after {(millis() - start):5.1F}ms')\n",
    "\n",
    "images_data = None # free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluation\n",
    "Next up, we'll show the results of our training process for the different scenes and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.evaluator import SceneCoordinateEvaluator\n",
    "from source.visualization import draw_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact, that the feature generation process may lead to invalid features, we have a look at how many of the sampled point from the test data return a valid result. A feature is considered invalid if the shift during feature generation leads to indices that lay outside the image boundary or have an invalid depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = SceneCoordinateEvaluator()\n",
    "valid_predictions = eval.get_valid_predictions(forest_predictions)\n",
    "\n",
    "total_num_predictions = (NUM_TEST_IMAGES * NUM_SAMPLES_PER_IMAGE * params[\"NUM_TREES\"])\n",
    "valid_num_predictions = valid_predictions.shape[0]\n",
    "\n",
    "print(f'The forest exhibits {(valid_num_predictions / total_num_predictions):.2%} valid predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we calculate the average deviation of the predicted 3D cooordinate with respect to the ground truth. This is calculated for each tree in the forest and as total deviation using the L2-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate L2-norm error between predicted and ground truth world coordinates\n",
    "errors = eval.get_prediction_error(forest_predictions, w_s)\n",
    "\n",
    "# plot mean error and variance per tree\n",
    "plt.figure(figsize=(12,6))\n",
    "for i, err in enumerate(errors):\n",
    "    plt.hist(err, bins=100, fill=False, histtype='step', label=f'Tree {i+1}')\n",
    "    print(f'Tree {i+1}: average deviation = [{np.mean(err):1.3E} +/- {np.var(err):1.3E}] m')\n",
    "    \n",
    "plt.xlabel('Deviation [m]')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# plot total error for forest\n",
    "avg_deviation = np.mean([np.mean(err) for err in errors])\n",
    "var_deviation = np.mean([np.var(err) for err in errors])\n",
    "\n",
    "print(f\"\\nTotal average deviation = [{avg_deviation:1.3E} +/- {var_deviation:1.3E}] m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all forests the majority of deviations is between 0 and 2 meters. This may look fairly bad, considering that the RANSAC samples random coordinates from the trees. But, due to the greedy optimization approach, the camera pose optimization still produces adequate results as shown in the sections below. However, there is still potential to optimize our Regression Forest.\n",
    "\n",
    "Next up it is also interseting to look at the average result of all trees in a forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_forest_error = eval.get_mean_forest_error(forest_predictions, w_s)\n",
    "np.save(f\"forest_err_{SCENE}.npy\", np.array(mean_forest_error))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(mean_forest_error, bins=100, fill=False, histtype='step', color=\"lightblue\", label=f'Mean Forest Error')    \n",
    "plt.xlabel('Deviation [m]')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [\"chess\", \"fire\", \"heads\", \"office\", \"pumpkin\", \"redkitchen\", \"stairs\"]\n",
    "mean_forest_errors = []\n",
    "for sc in SCENES:\n",
    "    mean_forest_errors.append(np.load(f\"forest_err_{sc}.npy\"))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for i, err in enumerate(mean_forest_errors):\n",
    "    plt.hist(err, bins=100, fill=False, histtype='step', label=f'Scene {SCENES[i]}')\n",
    "    #print(f'Tree {i+1}: average deviation = [{np.mean(err):1.3E} +/- {np.var(err):1.3E}] m')\n",
    "    \n",
    "plt.xlabel('Deviation [m]')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Finally, we plot a pointcloud to show some fancy graphical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pointcloud(valid_predictions) # opens an external window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predicting Camera Poses\n",
    "Let's have a look at the predicted camera poses of the RANSAC optimization. We use a trained forest that has been loadded in the previous cells and pass it to the RANSAC optimizer. For validation purposes we are using a number `NUM_TEST_IMAGES` of unseen test images. The camera poses are then predicted for each test image and compared to the corresponding ground truths.\n",
    "\n",
    "Per Image ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ransac import Ransac, parallel\n",
    "from source.evaluator import PoseEvaluator\n",
    "import multiprocessing\n",
    "\n",
    "NUM_TEST_IMAGES = 500\n",
    "\n",
    "# sample images from test data set\n",
    "test_indices = np.random.choice(params['TEST_INDICES'], NUM_TEST_IMAGES, replace = False)\n",
    "images_data = DataLoader(DATA_PATH).load_dataset(SCENE, test_indices)\n",
    "\n",
    "# get ground truth camera poses from image data\n",
    "ground_truth_poses = images_data[2]\n",
    "\n",
    "print(f\"Predicting poses of scene {SCENE} with {NUM_TEST_IMAGES} test images...\")\n",
    "start = millis()\n",
    "\n",
    "# start parallel execution of ransac\n",
    "rans = []\n",
    "for i in range(NUM_TEST_IMAGES):\n",
    "    rans.append(Ransac((images_data[0][i][np.newaxis, : ,:], images_data[1][i][np.newaxis, : ,:], images_data[2][i][np.newaxis, : ,:]), forest, np.array([i])))\n",
    "\n",
    "# obtain predicted poses from multiprocessing worker\n",
    "with  multiprocessing.Pool(processes= multiprocessing.cpu_count()) as pool:\n",
    "   poses = pool.map(parallel, rans)\n",
    "\n",
    "# map poses from workers\n",
    "predicted_poses = np.zeros((NUM_TEST_IMAGES, 4, 4))\n",
    "for entry in poses:\n",
    "    pose = entry[0]\n",
    "    index = entry[1]\n",
    "    predicted_poses[index,:,:] = pose\n",
    "\n",
    "print(f'Finished after {(millis() - start):5.1F}ms')\n",
    "\n",
    "images_data = None # free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Evaluation\n",
    "For each pose the translational and angular error is measured in order to evaluate the predicted camera poses. If both are below some threshold `THRESHOLD_TRANSLATIONAL` and `THRESHOLD_ANGULAR`, the pose is considered to be correct. Initially, we use error thresholds of 5cm and 5° as in the corresponding paper. \n",
    "\n",
    "In the following, the histograms for translational and angular errors are plotted and evaluated. Then the total amount of correctly classified poses is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.evaluator import PoseEvaluator\n",
    "\n",
    "THRESHOLD_TRANSLATIONAL = 5.  # cm\n",
    "THRESHOLD_ANGULAR = 5.        # degree\n",
    "\n",
    "evaluator = PoseEvaluator(THRESHOLD_TRANSLATIONAL, THRESHOLD_ANGULAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate translational error\n",
    "error_translation = evaluator.get_translational_error(predicted_poses, ground_truth_poses)\n",
    "\n",
    "print(f'Average Translational Error = [{np.mean(error_translation):1.3E} +/- {np.var(error_translation):1.3E}] m')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(error_translation, bins=100, fill=False, histtype='step', label=f'Translational Error')    \n",
    "plt.xlabel('Deviation [m]')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the angular error\n",
    "error_angular = evaluator.get_angular_error(predicted_poses, ground_truth_poses)\n",
    "\n",
    "print(f'Average Angular Error = [{np.mean(error_angular):1.3E} +/- {np.var(error_angular):1.3E}]°')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(error_translation, bins=100, fill=False, histtype='step', label=f'Translational Error')    \n",
    "plt.xlabel('Deviation [degree]')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = evaluator.evaluate(predicted_poses, ground_truth_poses)\n",
    "\n",
    "print(f'The amount of correctly classified poses with \\\n",
    "translational threshold = {THRESHOLD_TRANSLATIONAL} cm and \\\n",
    "angular threshold = {THRESHOLD_ANGULAR}° \\n \\\n",
    "is {error:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "160da64e0deff7d0df9af07f9cedba48bcfd44cf0926ed9afde6759be0b531b0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('3dcv-mp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
