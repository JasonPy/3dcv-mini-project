% This version of CVPR template is provided by Ming-Ming Cheng.
% Please leave an issue if you found a bug:
% https://github.com/MCG-NKU/CVPR_Template.

%\documentclass[review]{cvpr}
\documentclass[final]{cvpr}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}


\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\confYear{CVPR 2022}
%\setcounter{page}{4321} % For final version only


\begin{document}

%%%%%%%%% TITLE
\title{Camera Pose Estimation using Regression Tree and RANSAC Optimization}

\author{Falk Ebert\\
4018276\\
{\tt\small f.ebert@stud.uni-heidelberg.de}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Jason Pyanowski\\
3663907\\
{\tt\small j.pyanowski@stud.uni-heidelberg.de}
\and
Marven Hinze\\
3664283\\
{\tt\small ---@stud.uni-heidelberg.de}
\and
Nadine Theissen\\
3475402\\
{\tt\small ---@stud.uni-heidelberg.de}
}

\maketitle


%%%%%%%%% ABSTRACT
\begin{abstract}
   
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
cite it~\cite{shotton2013}

% What are we doing in this project?
%	-> Scene coordinate regression
% 	-> Camera pose estimation
% Why is this important?

% What data is given
% 	-> Image data including depth, camera poses

%-------------------------------------------------------------------------
\subsection{Related Work}


\section{Methods}
%-------------------------------------------------------------------------
This section gives an overview of the methods used in this project. We will discuss
the concept of regression forests including feature extraction and the RANSAC algorithm
used for estimating the camera pose from the image data. We will not discuss all aspects
in full detail but only provide further explanations where we find it relevant
for the presentation of our work and results.

\subsection{Regression Forest}

In this project we use a regression forest to predict scene coordinates for a given
sample image coordinate as suggested in \cite{shotton2013}. In this section we will
give some background on the concept of regression forests, the pixel coordinate
labeling and the image-feature extraction on which the forests base their predictions.\\

\subsubsection{Decision Trees}
A regression forest consists of a number $N$ of regression trees, which each consist of
of root node and it's children. We consider the special case of binary decision trees
where each node (unless it is a leaf node) has a left and a right child. At each node
the input data ()

\subsubsection{Image Features}
In order to use a descision tree to infer scene coordinates from the pixel coordinates,
it is necessary to calculate features associated with a given pixel cooridnate from the
image data. 


%-------------------------------------------------------------------------
\subsection{RANSAC Optimization}

%-------------------------------------------------------------------------
\subsection{Data Preperation}
To train the regression forest the 7-scenes datset~\cite{glocker2013} is utilized. 
Each scene consists of multiple image sequences that cover the are of interest. Using a RGB-D 
Kinect camera, depth information for each pixel is extracted. The resolution of the $24$ 
bit RGB-images is $640\times480$ pixels and the corresponding $16$ bit depth map is given 
in millimeters. For each image a $4\times4$ ground truth camera pose in homogenous coordinates 
is provided, which allows to validate the estimated camera pose matrix for a given image. 

The datasets are split randonly into train and test according to~\cite[Table 1]{shotton2013}. 

%-------------------------------------------------------------------------
\section{Experiment Evaluation}
To validate the implementation, the estimated camera poses are compared to the results 
of~\cite{shotton2013}. Therefore, the translational and angular error of the estimated camera 
poses with respect to the ground truth is measured. In particular, a translational error of at 
most $5$cm and angular error of at most $5^{\circ}$ is considered to be a correctly predicted pose. 

Let the estimated pose matrix $H_{est}$ and the ground truth $H_{gt}$ be $4 \times 4$ matrices
in homogeneous coordinates. Then the translational error $\varepsilon_t$ is obtained by using the 
coordinate-wise $L_2$-norm of the translation vectors $T_{est}, T_{gt} \in \mathbb{R}^3$ as 
\begin{align}
    \varepsilon_t &= \sqrt{(T_{est} - T_{gt})^2}
\end{align}

To compare two rotational poses, the angle of the difference rotation matrix $R$ is utilized. 
Let denote the whole $3\times3$ upper-left matrix of $H_{est}$ and $H_{gt}$ as $R_{est}$ and 
$R_{gt}$ repectively. They refer to the rotational poses and the difference rotation can be computed 
by $R = R_{est}R_{gt}^T$. The angle $\varepsilon_r$ between those two rotation matrices is then obtained as
\begin{align}
    \varepsilon_r &= arccos \frac{tr(R)-1}{2}
\end{align}
where $tr(R)$ is the tracce of a matrix.


%-------------------------------------------------------------------------
\section{Results}


{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
